{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using distinct trainning and test paths\n",
      "** Succesfully created experiment folder! **\n",
      "** Created and modified temp lisp file **\n",
      "** running lisp **\n",
      " \n",
      "** we got here! done! **\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import numpy as np\n",
    "from run import RunJupyterExperiment\n",
    "import data_extractor\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section1: run experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You need to specify your paths in this block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_history_folder = 'experiment_history/'\n",
    "training_folder_path = './dataset/bach_dataset/'\n",
    "test_folder_path = './dataset/shanx_dataset/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You don't need to change anything in the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    'experiment_history_folder':experiment_history_folder,\n",
    "    'train_test_path':[\n",
    "    training_folder_path,\n",
    "    test_folder_path, \n",
    "    ],\n",
    "    'trainp':None,\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using distinct trainning and test paths\n",
      "** Succesfully created experiment folder! **\n",
      "** Created and modified temp lisp file **\n",
      "** running lisp **\n",
      " \n",
      "** we got here! done! **\n"
     ]
    }
   ],
   "source": [
    "RunJupyterExperiment(configurations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section2: extracting data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the experiment data we just run above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 971/971 [00:00<00:00, 8165.77it/s]\n"
     ]
    }
   ],
   "source": [
    "newest_experiment_history_path = sorted(glob(experiment_history_folder+'*'))[-1]+'/' # sorted the order of the list\n",
    "selected_experiment_history_path = newest_experiment_history_path\n",
    "dat_file_path = sorted(glob(selected_experiment_history_path+'experiment_output_data_folder/*'))[0]\n",
    "all_song_dict = data_extractor.get_all_song_dict_from_dat(dat_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "choose which song you want to inspect by specifying the index "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Single song feature extraction ( Jump to next section if you need batch extraction )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "choose_song_index = 0                                             \n",
    "song_dict_of_interest= list(all_song_dict.values())[choose_song_index] # one of the testing song result info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- run this block to get ```aligned_surprise_with_onset```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned_surprise_with_onset: \n",
      "\n",
      "[[  0.          13.0368815 ]\n",
      " [ 18.          21.49184727]\n",
      " [ 24.          10.36179358]\n",
      " [ 36.          14.38636699]\n",
      " [ 48.           7.26311513]\n",
      " [ 66.          19.77576274]\n",
      " [ 72.          10.46272247]\n",
      " [ 96.           7.16554362]\n",
      " [108.          16.52401228]\n",
      " [120.           7.59347737]\n",
      " [132.           6.52908114]\n",
      " [144.           6.27771115]\n",
      " [192.          17.81342962]\n",
      " [210.          21.67754446]\n",
      " [216.          10.28764638]\n",
      " [228.          14.42123461]\n",
      " [240.           7.2654076 ]\n",
      " [258.          21.50496403]\n",
      " [264.          10.49416593]\n",
      " [288.           7.40585985]\n",
      " [300.          13.94678397]\n",
      " [312.          10.35315842]\n",
      " [336.           7.48152633]]\n"
     ]
    }
   ],
   "source": [
    "aligned_surprise_with_onset = data_extractor.get_aligned_surprise_with_onset_from_song_dict(song_dict_of_interest)\n",
    "\n",
    "print('aligned_surprise_with_onset: \\n')\n",
    "print(aligned_surprise_with_onset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- run this block to get ```surprise_sequence```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "surprise_sequence: \n",
      "\n",
      "[13.0368815  21.49184727 10.36179358 14.38636699  7.26311513 19.77576274\n",
      " 10.46272247  7.16554362 16.52401228  7.59347737  6.52908114  6.27771115\n",
      " 17.81342962 21.67754446 10.28764638 14.42123461  7.2654076  21.50496403\n",
      " 10.49416593  7.40585985 13.94678397 10.35315842  7.48152633]\n"
     ]
    }
   ],
   "source": [
    "surprise_sequence = data_extractor.get_surprise_from_song_dict(song_dict_of_interest)\n",
    "\n",
    "print('surprise_sequence: \\n')\n",
    "print(surprise_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- run this block to get ```note_distribution```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "note_distribution: \n",
      "\n",
      "[[0.         0.         0.         ... 0.00089381 0.00089381 0.00089381]\n",
      " [0.         0.         0.         ... 0.00089381 0.00089381 0.00089381]\n",
      " [0.         0.         0.         ... 0.00089381 0.00089381 0.00089381]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.00034009 0.00034009 0.00034009]\n",
      " [0.         0.         0.         ... 0.00089381 0.00089381 0.00089381]\n",
      " [0.         0.         0.         ... 0.00089381 0.00089381 0.00089381]]\n"
     ]
    }
   ],
   "source": [
    "note_distribution = data_extractor.get_note_distribution_from_song_dict(song_dict_of_interest)\n",
    "\n",
    "print('note_distribution: \\n')\n",
    "print(note_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "- run this block to get ```onset_sequence```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onset_sequence: \n",
      "\n",
      "[  0.  18.  24.  36.  48.  66.  72.  96. 108. 120. 132. 144. 192. 210.\n",
      " 216. 228. 240. 258. 264. 288. 300. 312. 336.]\n"
     ]
    }
   ],
   "source": [
    "onset_sequence = data_extractor.get_onset_from_song_dict(song_dict_of_interest)\n",
    "\n",
    "print('onset_sequence: \\n')\n",
    "print(onset_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Batch feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def song_wise_extraction(song_dict,extraction_methods):\n",
    "    single_song_data = []\n",
    "    for extraction in extraction_methods:\n",
    "        feature = extraction(song_dict).tolist()\n",
    "        single_song_data.append(feature)\n",
    "    #single_song_data = np.array(single_song_data,dtype=object)\n",
    "    return single_song_data\n",
    "\n",
    "def dataset_wise_extraction(all_song_dict,extraction_methods):\n",
    "    all_song_data = []\n",
    "    for index,song_dict in all_song_dict.items():\n",
    "        single_song_data = song_wise_extraction(song_dict,extraction_methods)\n",
    "        all_song_data.append(single_song_data)\n",
    "    all_song_data = np.array(all_song_data,dtype=object)\n",
    "    return all_song_data\n",
    "\n",
    "features_method_name_dict = {\n",
    "    'aligned_surprise_with_onset':data_extractor.get_aligned_surprise_with_onset_from_song_dict,\n",
    "    'surprise': data_extractor.get_surprise_from_song_dict,\n",
    "    'onset': data_extractor.get_onset_from_song_dict,\n",
    "    'note_distribution':data_extractor.get_note_distribution_from_song_dict,\n",
    "}\n",
    "\n",
    "dict_access_keys = lambda dic,l:[dic[x] for x in l]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Specify a list of feautures to extract (the available ones are in features_method_name_dict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "my_choice_of_extraction = [\n",
    "    'aligned_surprise_with_onset',\n",
    "    'surprise',\n",
    "    'onset',\n",
    "    'note_distribution',\n",
    "]\n",
    "\n",
    "data_to_export = dataset_wise_extraction(all_song_dict,dict_access_keys(features_method_name_dict,my_choice_of_extraction)).T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export data of interest to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def export(path,data):\n",
    "    for i,feature in enumerate(data_to_export):\n",
    "        feature_name = list(features_method_name_dict.keys())[i]\n",
    "        scipy.io.savemat(path+feature_name+'.mat', mdict={feature_name: np.array(feature)})\n",
    "    print('exported data to '+path )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify destination for exporting the file containing the data above\n",
    "\n",
    "do the export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exported data to experiment_history/11-16-20_16.36.04/\n"
     ]
    }
   ],
   "source": [
    "your_file_path = selected_experiment_history_path\n",
    "export(your_file_path,data_to_export)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
